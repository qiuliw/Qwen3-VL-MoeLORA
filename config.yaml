# Qwen3-VL-MoeLoRA 训练配置文件
# 参考 LLaMAFactory 风格

# ==================== 模型配置 ====================
model:
  # 基础模型路径（本地路径或 HuggingFace 模型 ID）
  model_name_or_path: "./qwen3-vl-4b-instruct"
  
  # 模型配置
  trust_remote_code: true
  use_cache: false
  gradient_checkpointing: true

# ==================== 数据配置 ====================
dataset:
  # 训练数据 JSON 文件路径
  train_json_path: "data_vl.json"
  
  # 最大训练样本数量（用于测试，设置为 null 或 -1 表示使用全部数据）
  max_train_samples: 10
  
  # 测试数据数量（从训练数据末尾取）
  test_samples: 4
  
  # 数据预处理配置
  max_length: 8192
  image_resize_height: 280
  image_resize_width: 280

# ==================== 训练配置 ====================
training:
  # 输出目录
  output_dir: "./output/Qwen3-VL-4Bmoelora"
  
  # 批次大小
  per_device_train_batch_size: 1
  gradient_accumulation_steps: 8
  
  # 训练轮数
  num_train_epochs: 5
  
  # 保存和日志
  save_steps: 100
  logging_steps: 10
  logging_first_step: 5
  
  # 学习率
  learning_rate: 1.0e-4
  
  # 精度
  fp16: true
  
  # 其他配置
  save_on_each_node: true
  gradient_checkpointing: true

# ==================== LoRA/MoeLoRA 配置 ====================
lora:
  # LoRA 类型: "lora" 或 "moelora"
  lora_type: "moelora"
  
  # LoRA 基础配置
  r: 8
  lora_alpha: 16
  lora_dropout: 0.05
  
  # MoeLoRA 专用配置（仅当 lora_type 为 "moelora" 时生效）
  num_experts: 2  # 专家数量（8G显存建议≤2）
  gate_dropout: 0.1  # 路由门控的dropout
  
  # 目标模块（与原始代码保持一致）
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "visual_q_proj"
    - "visual_k_proj"

# ==================== 量化配置 ====================
quantization:
  # 是否启用 4-bit 量化
  load_in_4bit: true
  
  # BitsAndBytes 配置
  bnb_4bit_use_double_quant: true
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_compute_dtype: "float16"  # "float16" 或 "bfloat16"

# ==================== SwanLab 配置 ====================
swanlab:
  # 是否启用 SwanLab 可视化
  enabled: true
  
  # SwanLab API Key
  api_key: null  # 设置为你的 API Key，如果为 null 则交互式输入
  
  # 项目名称
  project: "Qwen3-VL-finetune"
  
  # 实验名称
  experiment_name: "qwen3-vl-coco2014"
  
  # 额外配置信息
  config:
    model: "https://huggingface.co/Qwen/Qwen3-VL-4B-Instruct"
    dataset: "https://modelscope.cn/datasets/modelscope/coco_2014_caption/quickstart"
    github: "https://github.com/datawhalechina/self-llm"
    prompt: "COCO Yes: "

# ==================== 其他配置 ====================
misc:
  # 随机种子
  seed: 42
  
  # 报告目标（"none" 表示不使用其他日志系统）
  report_to: "none"

